{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aeb5bb9",
   "metadata": {},
   "source": [
    "# Assignment 4: Diffusion Model\n",
    "\n",
    "In this assignment, you will implement a diffusion model from scratch and train it on the MNIST dataset. Diffusion models are a class of generative models that learn to gradually denoise random noise to generate realistic images. This assignment will guide you through the core components and training process of diffusion models.\n",
    "\n",
    "Useful links:\n",
    "1. [What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)\n",
    "2. [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)\n",
    "\n",
    "Please:\n",
    "* Fill out the code marked with `TODO` or `Your code here`. You are allowed to split functions or visualizations to different files for more flexibility as long as your output includes what we asked.\n",
    "* Reuse or modify visualization code from Assignment 2 for creating necessary visualizations.\n",
    "* Submit the notebook with all original outputs. If the output is included from another file, please include them into your folder. \n",
    "* Answer questions at the end of the notebook. Write your answere in the notebook.\n",
    "\n",
    "**Please reserve enough time for this assignment given the potential amount of time for training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f69f1260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanchandra/Documents/CS378_GenAI/Assignment4/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:279: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c533b952",
   "metadata": {},
   "source": [
    "## Part 1: Implementing the U-Net (30 pt)\n",
    "\n",
    "In this part, you will implement a U-Net style model that serves as the backbone for the diffusion process. The model takes noisy images and their corresponding timesteps as input and predicts the noise that was added to the original images.\n",
    "\n",
    "Please fill out the code in `diffusion.DiffusionModel` then run the following code for test. For the time embedding, you can only use one embedding layer and concatenate it with the feature. The attention layer is not enforced given the computation resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3754da8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiffusionModel implementation is correct!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusion import DiffusionModel\n",
    "\n",
    "def check_diffusion_model(model_class):\n",
    "    \"\"\"Verify that the DiffusionModel class is correctly implemented.\"\"\"\n",
    "    try:\n",
    "        channels = 1\n",
    "        image_size = 28\n",
    "        noise_steps = 1000\n",
    "        model = model_class(image_size=image_size, channels=channels)\n",
    "        \n",
    "        # Test forward pass with random inputs\n",
    "        batch_size = 4\n",
    "        x = torch.randn(batch_size, channels, image_size, image_size)\n",
    "        t = torch.randint(0, noise_steps, (batch_size,))\n",
    "        \n",
    "        output = model(x, t)\n",
    "        \n",
    "        # Check output shape\n",
    "        expected_shape = (batch_size, channels, image_size, image_size)\n",
    "        assert output.shape == expected_shape, f\"Expected output shape {expected_shape}, got {output.shape}\"\n",
    "        \n",
    "        print(\"DiffusionModel implementation is correct!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"DiffusionModel check failed: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "check_diffusion_model(DiffusionModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c35ca5",
   "metadata": {},
   "source": [
    "## Part 2: Implementing the Diffusion Process (30 pt)\n",
    "\n",
    "In this part, you will implement the core diffusion process, including the forward diffusion (adding noise) and the denoising process. This includes setting up the noise schedule and implementing functions for noise addition and sampling.\n",
    "\n",
    "Please fill out the code in `diffusion.DiffusionProcess` then run the following code for test. Note that this test only tests the correctness of the output format. You need to be careful about the actual math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959e2089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiffusionProcess implementation is correct!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusion import DiffusionProcess\n",
    "\n",
    "def check_diffusion_process(diffusion_class):\n",
    "    \"\"\"Verify that the DiffusionProcess class is correctly implemented.\"\"\"\n",
    "    try:\n",
    "        channels = 1\n",
    "        image_size = 28\n",
    "        noise_steps = 1000\n",
    "        diffusion = diffusion_class(image_size=image_size, channels=channels, noise_steps=noise_steps)\n",
    "        \n",
    "        # Test add_noise function\n",
    "        batch_size = 4\n",
    "        x = torch.randn(batch_size, channels, image_size, image_size)\n",
    "        t = torch.randint(0, noise_steps, (batch_size,))\n",
    "        \n",
    "        noisy_x, noise = diffusion.add_noise(x, t)\n",
    "        assert noisy_x.shape == x.shape, f\"Expected noisy_x shape {x.shape}, got {noisy_x.shape}\"\n",
    "        assert noise.shape == x.shape, f\"Expected noise shape {x.shape}, got {noise.shape}\"\n",
    "        \n",
    "        # Test train_step function\n",
    "        loss = diffusion.train_step(x)\n",
    "        assert isinstance(loss, float), f\"Expected loss to be a float, got {type(loss)}\"\n",
    "        \n",
    "        print(\"DiffusionProcess implementation is correct!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"DiffusionProcess check failed: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "check_diffusion_process(DiffusionProcess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c472c0b",
   "metadata": {},
   "source": [
    "## Part 3: Training and Sampling (20 points)\n",
    "\n",
    "In this part, you will implement the training loop for the diffusion model and the functions for generating and visualizing samples. Please try to follow the assignment you have written and use the `DiffusionModel`  and `DiffusionProcess` above for write your training function. You should write your training code in a standalone python file.\n",
    "\n",
    "Please include the training curves and the sampled results below. You can reuse the visualization code we provided in the GAN assignment.\n",
    "\n",
    "You can include an image like:\n",
    "\n",
    "![image](./DDPM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56263487",
   "metadata": {},
   "source": [
    "## Part 4: Analysis and Visualization (20 points)\n",
    "\n",
    "Answer the question with your analysis. Most of the questions are open-ended. We are looking for yourown observasion from the experiments you did.\n",
    "\n",
    "1. How does the choice of noise schedule (beta values) affect the training stability and sample quality? Try at least one alternative to the linear schedule (e.g., cosine or quadratic) and compare the results.\n",
    "\n",
    "[Answer]:\n",
    "\n",
    "2. Based on your observations, at which timesteps (early, middle, or late in the diffusion process) does the model seem to struggle the most with accurately predicting the noise (looking into loss)? Why do you think this occurs?\n",
    "\n",
    "[Answer]:\n",
    "\n",
    "3. Perform interpolation between two noise vectors and analyze the resulting generated images. Is the transition smooth? What does this tell you about the model's learned latent space?\n",
    "\n",
    "[Answer]:\n",
    "\n",
    "4. Recall Assignment 2, we implemented GAN. compare your diffusion model with GANs in terms of:\n",
    "* Training stability\n",
    "* Sample quality\n",
    "* Diversity of samples\n",
    "* Computational requirements\n",
    "* Anything else you find interesting\n",
    "\n",
    "[Answer]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c688de0",
   "metadata": {},
   "source": [
    "## Extra Credit: Diffusion Model on CIFAR 10 (20 pt)\n",
    "\n",
    "In this extra credit assignment, you'll extend your Diffusion implementation to handle the more complex CIFAR-10 dataset.\n",
    "\n",
    "You should design your own network architectures, considering factors like the increased complexity of RGB images, memory efficiency, and training stability. The basic code structure from the MNIST implementation can serve as a reference, but you'll need to modify the network dimensions and potentially add more capacity to handle the increased complexity.\n",
    "\n",
    "Your submission should include complete implementation code (in a standalone file), training curves, generated imagesamples (inclue below), and a brief analysis (1-2 paragraphs) comparing your CIFAR-10 results with your MNIST implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da5e90",
   "metadata": {},
   "source": [
    "## Extra Credit: DDIM Sampler Implementation (20 points)\n",
    "\n",
    "Implement the Denoising Diffusion Implicit Models (DDIM) sampling method, which allows for faster sampling based on paper [Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502).\n",
    "\n",
    "1. Implement the DDIM sampling algorithm based on the paper.\n",
    "2. Compare DDIM sampling with the standard DDPM sampling in terms of:\n",
    "* Sampling speed\n",
    "* Sample quality\n",
    "* Number of required steps\n",
    "\n",
    "3. Experiment with different numbers of DDIM steps and analyze the tradeoff between speed and quality.\n",
    "\n",
    "Your submission should include complete implementation code (can be in another python file), generated imagesamples (using the same MNIST model you presented above), and a brief analysis (1-2 paragraphs) comparing DDIM and DDPM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
